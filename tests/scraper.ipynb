{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_DIR /home/sohaib/Documents/scrapers/scrappers/\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "BASE_DIR = \"/home/sohaib/Documents/scrapers/scrappers/\"\n",
    "print(\"BASE_DIR\", BASE_DIR)\n",
    "sys.path.append(BASE_DIR )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Glassdoor scraper.\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from urllib.parse import urljoin\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from scrappers.Scraper import Scrapper\n",
    "from scrappers.shared_attr import posted_date_list, title_keywords\n",
    "from scrappers.helper import get_title\n",
    "from shared_layer.logger import logger\n",
    "\n",
    "\n",
    "\n",
    "class Glassdoor(Scrapper):  # Inherit from Scrapper\n",
    "    \"\"\"Scraping Glassdoor job leads\n",
    "\n",
    "    Args:\n",
    "        - base_url  (str): Base url of the Glassdoor\n",
    "        - job_portal (str): Job portal url\n",
    "        - headers  (str) : Headers need to scrap Glassdoor\n",
    "        - remove_companies (list): Do not scrap data of companies present in list\n",
    "        - tags (list): tags associated with the lead collected with this scrapper\n",
    "        - delay (int): Delay between next start of scrapper (1st day 12:00) next start after 1380 hours\n",
    "        - name (str): Name of a scrapper\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.glassdoor_url_list = [\n",
    "            [\n",
    "                \"https://www.glassdoor.com/Job/us-{}-jobs-SRCH_IL.0,2_IN1_KO3,13_IP{}.htm?fromAge=1&radius=25\",\n",
    "                \"United States\",\n",
    "            ],\n",
    "            [\n",
    "                \"https://www.glassdoor.com/Job/australia-{}-jobs-SRCH_IL.0,9_IN16_KO10,13_IP{}.htm?fromAge=1&radius=25\",\n",
    "                \"Australia\",\n",
    "            ],\n",
    "            [\n",
    "                \"https://www.glassdoor.com/Job/indonesia-{}-jobs-SRCH_IL.0,9_IN113_KO10,27_IP{}.htm?fromAge=1\",\n",
    "                \"Indonesia\",\n",
    "            ],\n",
    "            [\n",
    "                \"https://www.glassdoor.com/Job/dubai-{}-jobs-SRCH_IL.0,5_IC2204498_KO6,12.htm?fromAge=3\",\n",
    "                \"Dubai\",\n",
    "            ],\n",
    "            [\n",
    "                \"https://www.glassdoor.com/Job/bahrain-{}-jobs-SRCH_IL.0,7_IN21_KO8,11.htm?fromAge=3\",\n",
    "                \"Bahrain\",\n",
    "            ],\n",
    "            [\n",
    "                \"https://www.glassdoor.com/Job/qatar-{}-jobs-SRCH_IL.0,5_IN199_KO6,9.htm?fromAge=3\",\n",
    "                \"Qatar\",\n",
    "            ],\n",
    "            [\n",
    "                \"https://www.glassdoor.com/Job/malaysia-{}-jobs-SRCH_IL.0,8_IN170_KO9,26_IP{}.htm?fromAge=1\",\n",
    "                \"Malaysia\",\n",
    "            ],\n",
    "            [\n",
    "                \"https://www.glassdoor.com/Job/new-zealand-{}-jobs-SRCH_IL.0,11_IN186_KO12,29_IP{}.htm?fromAge=1\",\n",
    "                \"New Zealand\",\n",
    "            ],\n",
    "            [\n",
    "                \"https://www.glassdoor.com/Job/singapore-{}-jobs-SRCH_IL.0,9_IC3235921_KO10,27_IP{}.htm?fromAge=1\",\n",
    "                \"Singapore\",\n",
    "            ],\n",
    "            [\n",
    "                'https://www.glassdoor.com/Job/vietnam-{}-jobs-SRCH_IL.0,7_IN251_KO8,25_IP{}.htm?fromAge=1',\n",
    "                'Vietnam',\n",
    "            ],\n",
    "            [\n",
    "                'https://www.glassdoor.com/Job/thailand-{}-jobs-SRCH_IL.0,8_IN229_KO9,16_IP{}.htm?fromAge=1',\n",
    "                'Thailand',\n",
    "            ],\n",
    "            [\n",
    "                \"https://www.glassdoor.com/Job/united-arab-emirates-{}-jobs-SRCH_IL.0,20_IN6_KO21,38_IP{}.htm?fromAge=1\",\n",
    "                \"United Arab Emirates\",\n",
    "            ],\n",
    "            [\n",
    "                \"https://www.glassdoor.com/Job/saudi-arabia-{}-jobs-SRCH_IL.0,12_IN207_KO13,16_IP{}.htm?fromAge=1\",\n",
    "                \"Saudi Arabia\",\n",
    "            ],\n",
    "            [\n",
    "                \"https://www.glassdoor.com/Emploi/france-{}-emplois-SRCH_IL.0,6_IN86_KO7,10_IP{}.htm?fromAge=1\",\n",
    "                \"France\",\n",
    "            ],\n",
    "            [\n",
    "                \"https://www.glassdoor.com/Job/germany-{}-jobs-SRCH_IL.0,7_IN96_KO8,25_IP{}.htm?fromAge=1\",\n",
    "                \"Germany\",\n",
    "            ],\n",
    "            [\n",
    "                \"https://www.glassdoor.com/Job/hungary-{}-jobs-SRCH_IL.0,7_IN111_KO8,21_IP{}.htm?fromAge=1\",\n",
    "                \"Hungary\",\n",
    "            ],\n",
    "            [\n",
    "                \"https://www.glassdoor.com/Job/switzerland-{}-jobs-SRCH_IL.0,11_IN226_KO12,25_IP{}.htm?fromAge=1\",\n",
    "                \"Switzerland\",\n",
    "            ],\n",
    "            [\n",
    "                \"https://www.glassdoor.com/Job/sweden-{}-jobs-SRCH_IL.0,6_IN223_KO7,20_IP{}.htm?fromAge=1\",\n",
    "                \"Sweden\",\n",
    "            ],\n",
    "            [\n",
    "                \"https://www.glassdoor.com/Job/denmark-{}-jobs-SRCH_IL.0,7_IN63_KO8,14_IP{}.htm?fromAge=1\",\n",
    "                \"Denmark\",\n",
    "            ],\n",
    "            [\n",
    "                \"https://www.glassdoor.com/Empleo/spain-{}-empleos-SRCH_IL.0,5_IN219_KO6,19_IP{}.htm?fromAge=1\",\n",
    "                \"Spain\",\n",
    "            ],\n",
    "        ]\n",
    "        self.base_url = \"https://www.glassdoor.com/\"\n",
    "        self.job_portal = \"\"\n",
    "        self.headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "            \"Chrome/83.0.4103.116 Safari/537.36\"\n",
    "        }\n",
    "        self.remove_companies = []\n",
    "        self.tags = []\n",
    "        self.name = \"glassdoor.com\"\n",
    "        self.logger = logger.get_logger(self.name)\n",
    "        self.lead_collected = 0\n",
    "        print(\"Initializing Glassdoor.com\")\n",
    "\n",
    "    def __del__(self):\n",
    "        \"\"\"Calling destructor for deleting db object when object is destroyed\n",
    "\n",
    "        Returns:\n",
    "            SuperClass : Calls super class desctructor\n",
    "        \"\"\"\n",
    "        self.logger.info(f\"Closing {self.name} db Object\")\n",
    "        return super().__del__()\n",
    "\n",
    "    def store_jobs(self, title, company, city, state, job_url, posted_date, country):\n",
    "\n",
    "        valid = get_title(title)\n",
    "        if valid and \"recruit\" not in company:\n",
    "            if company is not None:\n",
    "\n",
    "                current_item = {\n",
    "                    \"Title\": title,\n",
    "                    \"Company\": company,\n",
    "                    \"City\": city,\n",
    "                    \"State\": state,\n",
    "                    \"Platform\": self.name,\n",
    "                    \"LeadUrl\": job_url,\n",
    "                    \"Posted_date\": posted_date,\n",
    "                    \"Region\": country\n",
    "                }\n",
    "                # add in lead list that will be processed in run()\n",
    "                self.publish_message(current_item)\n",
    "                self.lead_collected += 1\n",
    "                self.logger.info(f\"Lead Collected: {self.lead_collected}\")\n",
    "\n",
    "    def get_jobs(self, job_collection, country):\n",
    "        \"\"\"Get New Jobs(leads) and save in the database jobs_leads table\n",
    "\n",
    "        Args\n",
    "            - job_collection  (list): List of jobs elements\n",
    "            - country (str): Target Country / Remote\n",
    "            - company_list  (list) : list of already scraped companies\n",
    "            - db1 (DataBase): Database instance object to interact with database\n",
    "\n",
    "        return\n",
    "            - void\n",
    "\n",
    "        \"\"\"\n",
    "        for job in job_collection:\n",
    "\n",
    "            try:\n",
    "                job_container = job.findAll(\"div\")[1]\n",
    "            except:\n",
    "                job_container = job.find(\"div\", class_=\"jobContainer\")\n",
    "            try:\n",
    "                company = job_container.find(\"a\").text.strip()\n",
    "            except:\n",
    "                company = None\n",
    "\n",
    "            try:\n",
    "                job_url = job_container.find(\"a\")[\"href\"]\n",
    "                job_url = urljoin(self.base_url, job_url)\n",
    "            except:\n",
    "                job_url = None\n",
    "\n",
    "            try:\n",
    "                title = job_container.findAll(\"a\")[1].text.strip()\n",
    "            except:\n",
    "                title = None\n",
    "            try:\n",
    "                location = job_container.find(\n",
    "                    \"div\", class_=\"jobInfoItem empLoc flex-wrap\"\n",
    "                ).span.text.strip()\n",
    "            except:\n",
    "                try:\n",
    "                    location = job_container.find(\n",
    "                        \"div\", class_=\"d-flex flex-wrap css-11d3uq0 e1rrn5ka1\"\n",
    "                    ).span.text.strip()\n",
    "                except:\n",
    "                    location = None\n",
    "            try:\n",
    "                city = location.split(\",\")[0]\n",
    "            except:\n",
    "                city = location\n",
    "            try:\n",
    "                state = location.split(\",\")[1]\n",
    "            except:\n",
    "                state = None\n",
    "            try:\n",
    "                posted_date = job_container.find(\n",
    "                    \"div\", {\"data-test\": \"job-age\"}\n",
    "                ).text.strip()\n",
    "            except:\n",
    "                posted_date = None\n",
    "\n",
    "            if posted_date in posted_date_list \\\n",
    "                    and company is not None \\\n",
    "                    and company not in self.remove_companies:\n",
    "                \n",
    "                self.logger.info(f\"Sotring Job: {title}\")\n",
    "                self.store_jobs(title, company, city,\n",
    "                                  state, job_url, posted_date, country)\n",
    "\n",
    "    def main_code(self, url_list):\n",
    "        \"\"\"Extract Jobs(leads) against every glassdoor_url\n",
    "\n",
    "        Args\n",
    "            - url_list  (list): List of glassdoor links with region ---(keywords.py - glassdoor_url_list)\n",
    "\n",
    "        return\n",
    "            - void\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        for glassdoor_url in url_list[:2]:\n",
    "            # This page_url is incomplete and needs formatting down.\n",
    "            page_url = glassdoor_url[0]\n",
    "            region = glassdoor_url[1]\n",
    "\n",
    "            for keyword in title_keywords[:2]:\n",
    "                print(\"Scraping\", keyword)\n",
    "                self.logger.info(f\"Scrapping keyword {keyword}\")\n",
    "                keyword = keyword.replace(\" \", \"-\")\n",
    "                try:\n",
    "                    pg = 0\n",
    "                    end = self.page_limit\n",
    "                    while pg < end:\n",
    "                        pg += 1\n",
    "                        # Format the page_url\n",
    "                        url = page_url.format(keyword, pg)\n",
    "                        self.logger.info(f\"url: {url}\")\n",
    "                        r = requests.get(url, headers=self.headers)\n",
    "                        print(url)\n",
    "                        print(self.headers)\n",
    "                        print(r.status_code)\n",
    "                        if r.status_code != 200:\n",
    "                            self.logger.info(f\"Status Code: {r.status_code}\")\n",
    "                            break\n",
    "\n",
    "                        time.sleep(2)\n",
    "                        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "                        try:\n",
    "                            article = soup.find(\n",
    "                                \"article\", id=\"MainCol\").find(\"ul\")\n",
    "                            job_collection = article.findAll(\"li\")\n",
    "                            if len(job_collection) != 0:\n",
    "                                self.get_jobs(\n",
    "                                    job_collection, region, self.remove_companies, self.db\n",
    "                                )\n",
    "                            else:\n",
    "                                break\n",
    "                        except:\n",
    "                            self.logger.exception(\n",
    "                                \"Error Occurred in main_code - Inner Except\"\n",
    "                            )\n",
    "                            break\n",
    "\n",
    "                except Exception as e:\n",
    "                    self.logger.exception(\n",
    "                        f\"Error Occurred in main_code - Outer Except {e}\")\n",
    "                    continue\n",
    "\n",
    "    def scrap(self, row_id):\n",
    "        \"\"\"Main function\n",
    "\n",
    "        Args:\n",
    "            scrapper_id (_type_): _description_\n",
    "            id (_type_): _description_\n",
    "        \"\"\"\n",
    "        try:\n",
    "            id = row_id\n",
    "            # Getting the starting time\n",
    "            start_time = time.time()\n",
    "            self.main_code(self.glassdoor_url_list)\n",
    "            # Getting time taken by the scrapper to get leads\n",
    "            time_taken_by_scrapper = (time.time() - start_time) // 60\n",
    "            # Logging things.\n",
    "            self.logger.info(f\" - leads Collected {self.lead_collected}\")\n",
    "        except Exception as e:\n",
    "            self.logger.exception(f\"Error Occured {self.name}\")\n",
    "            self.logger.info(f\" - leads Collected {self.lead_collected}\")\n",
    "            time_taken_by_scrapper = 0\n",
    "            \n",
    "        finally:\n",
    "            self.logger.info(f\" - Time Taken {time_taken_by_scrapper} minutes\")\n",
    "            # Updating the scrapper logs\n",
    "            status, message = self.update_logs_in_db(\n",
    "                time_taken_by_scrapper, self.lead_collected, id, self.logger\n",
    "            )\n",
    "\n",
    "\n",
    "def get_scraper():  # by default None\n",
    "    \"\"\"Get the scraper Object\n",
    "\n",
    "    Returns:\n",
    "       GlassDoor : Initialize Scraper object and return object\n",
    "    \"\"\"\n",
    "    return Glassdoor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initilising class Main\n",
      "Initializing Glassdoor.com\n",
      "Scraping python\n",
      "https://www.glassdoor.com/Job/us-python-jobs-SRCH_IL.0,2_IN1_KO3,13_IP1.htm?fromAge=1&radius=25\n",
      "{'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36'}\n",
      "403\n",
      "Scraping machine learning\n",
      "https://www.glassdoor.com/Job/us-machine-learning-jobs-SRCH_IL.0,2_IN1_KO3,13_IP1.htm?fromAge=1&radius=25\n",
      "{'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36'}\n",
      "403\n",
      "Scraping python\n",
      "https://www.glassdoor.com/Job/australia-python-jobs-SRCH_IL.0,9_IN16_KO10,13_IP1.htm?fromAge=1&radius=25\n",
      "{'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36'}\n",
      "403\n",
      "Scraping machine learning\n",
      "https://www.glassdoor.com/Job/australia-machine-learning-jobs-SRCH_IL.0,9_IN16_KO10,13_IP1.htm?fromAge=1&radius=25\n",
      "{'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36'}\n",
      "403\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# from scrappers.scrapper.glassdoor import get_scraper\n",
    "from shared_layer.postgres.database import Database\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def main(db_obj):\n",
    "\n",
    "    scrapper = get_scraper()\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO scraper_health (name)\n",
    "    VALUES (%s) RETURNING id;\n",
    "    \"\"\"\n",
    "    values = (scrapper.name,)\n",
    "    result = db_obj.execute(insert_query, values)\n",
    "    \n",
    "    scraper_health_id = 1\n",
    "    \n",
    "    scrapper.scrap(scraper_health_id)\n",
    "    print(result)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    db_obj = Database()\n",
    "    main(db_obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [403]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "url = \"https://www.glassdoor.com/Job/australia-machine-learning-jobs-SRCH_IL.0,9_IN16_KO10,26.htm?clickSource=searchBox\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36'}\n",
    "r = requests.get(url, headers=headers)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requests==2.25.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze|grep requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kafka_python",
   "language": "python",
   "name": "kafka_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
